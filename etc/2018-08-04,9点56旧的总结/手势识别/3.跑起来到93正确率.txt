
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img








##图像预处理:
#datagen = ImageDataGenerator(
#        rotation_range=10,
#        width_shift_range=1,
#        height_shift_range=1,
#        shear_range=0,
#        zoom_range=0.1,
#        horizontal_flip=True,
#        fill_mode='nearest')
# 
#img = load_img(r'C:/Users/张博/Desktop/cat.png')  # this is a PIL image
#x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)
#
#print(x.shape)
##下面的方法把3维图片变4维图片
#x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)#这个方法直接加一维
#
#print(x.shape)
## the .flow() command below generates batches of randomly transformed images
## and saves the results to the `preview/` directory
#i = 0
#for batch in datagen.flow(x, batch_size=1,
#                          save_to_dir='C:/Users/张博/Desktop/cat', save_prefix='cat'#默认的生成文件名前缀
#                          , save_format='png'):
#    i += 1
#    if i > 2:
#        break  # otherwise the generator would loop indefinitely
        
#img=load_img(r'C:/Users/张博/Desktop/cat/cat777777_0_1154.png')
#x = x.reshape((1,) + x.shape)
#print(x.shape)



from keras import backend as K
K.set_image_dim_ordering('th')
'''
if "image_dim_ordering": is "th" and "backend": "theano", your input_shape must be (channels, height, width)
if "image_dim_ordering": is "tf" and "backend": "tensorflow", your input_shape must be (height, width, channels)
因此上面我们需要设置 把模式切换成为'th'  .这点要注意.
'''











      
#搭建网络:

from keras.models import Sequential
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
 
model = Sequential()
model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))
 
# the model so far outputs 3D feature maps (height, width, features)





model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(10)) #因为我们分10累所以最后这里写10

model.add(Activation("softmax")) #softmax可以把10这个向量的分类凸显出来
 



'''
我现在所知道的解决方法大致只有两种，第一种就是添加dropout层，dropout的原理我就不多说了，
主要说一些它的用法，dropout可以放在很多类层的后面，用来抑制过拟合现象，常见的可以直接放在Dense层后面，
对于在Convolutional和Maxpooling层中dropout应该放置在Convolutional和Maxpooling之间，还是Maxpooling
后面的说法，我的建议是试！这两种放置方法我都见过，但是孰优孰劣我也不好说，但是大部分见到的都是放在
Convolutional和Maxpooling之间。关于Dropout参数的选择，这也是只能不断去试，但是我发现一个问题，
在Dropout设置0.5以上时，会有验证集精度普遍高于训练集精度的现象发生，但是对验证集精度并没有太大影响，
相反结果却不错，我的解释是Dropout相当于Ensemble，dropout过大相当于多个模型的结合，一些差模型会拉低
训练集的精度。当然，这也只是我的猜测，大家有好的解释，不妨留言讨论一下。 
当然还有第二种就是使用参数正则化，也就是在一些层的声明中加入L1或L2正则化系数，




keras.layers.normalization.BatchNormalization(
epsilon=1e-06, mode=0, axis=-1, momentum=0.9, weights=None, beta_init='zero',
 gamma_init='one')

'''






# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)
 
# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1./255)
 
# this is a generator that will read pictures found in
# subfolers of 'data/train', and indefinitely generate
# batches of augmented image data



train_generator = train_datagen.flow_from_directory(
        'C:/Users/张博/Desktop/图片总结/all_pic/test',  # this is the target directory
        target_size=(150, 150),  # all images will be resized to 150x150
        batch_size=20,          #说一般不操过128,取16,32差不多
        class_mode='sparse')  # since we use binary_crossentropy loss, we need binary labels




# this is a similar generator, for validation data
validation_generator = test_datagen.flow_from_directory(
        'C:/Users/张博/Desktop/图片总结/all_pic/valid',
        target_size=(150, 150),
        batch_size=20,
        class_mode='sparse')


#learning rate schedual 太重要了.经常发现到最后的学习效果提升很慢了.就是因为步子太大了扯蛋了.
def schedule(epoch):
    rate=0.7
    if epoch<3:
        return 0.002  #开始学的快一点
    if epoch<10:
        return 0.001
    if epoch<20:
        return 0.001*rate
    if epoch<30:
        return 0.001*rate**2
    if epoch<100:
       return 0.001*rate**3
    else:
        return 0.001*rate**4
    
learning_rate=keras.callbacks.LearningRateScheduler(schedule)
learning_rate2=keras.callbacks.ReduceLROnPlateau(factor=0.7)


adam=keras.optimizers.Adam( beta_1=0.9, beta_2=0.999, epsilon=1e-08,clipvalue=0.5)#lr=0.001
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=adam,
              metrics=['accuracy'])



#https://www.cnblogs.com/bamtercelboo/p/7469005.html       非常nice的调参总结


H=model.fit_generator(
        train_generator,
        steps_per_epoch=2000,     #  一个epoch训练多少次生成器给的数据,无所谓随便写一个就行,
                                  #也就是说一个epoch要训练多久,无所谓的一个数,但是如果看效果着急就设小一点.
        nb_epoch=500,         #总工迭代多少轮,越大越好
        validation_data=validation_generator,callbacks=[learning_rate,
         learning_rate2]
        )
 
#其实对于这个10分类问题就看acc指数就够了

print(H.history["loss"])
print(H.history["val_loss"])
print(H.history["acc"])


'''
batch的理解:
    有一堆人各种需求,总体放进去算loss函数肯定能让所有人的满意度提升
    但是人太多了,超大规模矩阵算梯度太慢了,所以选一小组人batch作为训练就可以了,让他们满足就行了.
    因为数据经过shuffle,所以每一次取得小组基本能代表所有人的需求.所以batch取大一点更能反映整体性质.
    但是单步计算可能就慢一些.所以一般16到100之见做选择.
'''




















        
        
        
        